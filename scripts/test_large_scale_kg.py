"""
å¤§è§„æ¨¡çŸ¥è¯†å›¾è°±æ„å»ºæµ‹è¯•

ä½¿ç”¨çœŸå®æ•°æ®æµ‹è¯•çŸ¥è¯†å›¾è°±çš„æ€§èƒ½å’Œè´¨é‡ã€‚
"""

import asyncio
import time
import json
import os
import sys
from typing import List, Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.feynman.core.graph.service import KnowledgeGraphService
from src.feynman.core.graph.schema import KnowledgeTriple
from mock_extractor import create_mock_kg_service


class KnowledgeGraphBenchmark:
    """çŸ¥è¯†å›¾è°±æ€§èƒ½æµ‹è¯•"""
    
    def __init__(self, use_mock: bool = True):
        if use_mock:
            print("ğŸ­ ä½¿ç”¨æ¨¡æ‹ŸæŠ½å–å™¨è¿›è¡Œæµ‹è¯•")
            # è¿™é‡Œä¼šåœ¨è¿è¡Œæ—¶å¼‚æ­¥åˆ›å»º
            self.kg_service = None
            self.use_mock = True
        else:
            self.kg_service = KnowledgeGraphService()
            self.use_mock = False
        self.results = {}
    
    async def _init_service(self):
        """å¼‚æ­¥åˆå§‹åŒ–æœåŠ¡"""
        if self.use_mock and self.kg_service is None:
            self.kg_service = await create_mock_kg_service()
    
    async def test_single_file_processing(self, file_path: str) -> Dict[str, Any]:
        """æµ‹è¯•å•ä¸ªæ–‡ä»¶çš„å¤„ç†æ€§èƒ½"""
        await self._init_service()  # ç¡®ä¿æœåŠ¡å·²åˆå§‹åŒ–
        
        print(f"ğŸ“„ æµ‹è¯•æ–‡ä»¶: {os.path.basename(file_path)}")
        
        # è·å–æ–‡ä»¶ä¿¡æ¯
        file_size = os.path.getsize(file_path)
        
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        print(f"   æ–‡ä»¶å¤§å°: {file_size / 1024:.1f} KB")
        print(f"   å­—ç¬¦æ•°: {len(content):,}")
        
        # æµ‹è¯•æ„å»ºè¿‡ç¨‹
        start_time = time.time()
        
        try:
            result = await self.kg_service.build_from_file(file_path)
            
            build_time = time.time() - start_time
            
            if result["success"]:
                stats = result.get("graph_stats", {})
                
                test_result = {
                    "file_path": file_path,
                    "file_size_kb": file_size / 1024,
                    "content_length": len(content),
                    "build_time_seconds": round(build_time, 2),
                    "triples_added": result.get("added_triples", 0),
                    "total_nodes": stats.get("num_nodes", 0),
                    "total_edges": stats.get("num_edges", 0),
                    "processing_speed_kb_per_sec": round((file_size / 1024) / build_time, 2),
                    "success": True
                }
                
                print(f"   âœ… å¤„ç†æˆåŠŸ")
                print(f"   â±ï¸ è€—æ—¶: {build_time:.2f}ç§’")
                print(f"   ğŸ“Š ä¸‰å…ƒç»„: {result.get('added_triples', 0)}")
                print(f"   ğŸŒ èŠ‚ç‚¹: {stats.get('num_nodes', 0)}, è¾¹: {stats.get('num_edges', 0)}")
                print(f"   ğŸš€ å¤„ç†é€Ÿåº¦: {test_result['processing_speed_kb_per_sec']} KB/ç§’")
                
            else:
                test_result = {
                    "file_path": file_path,
                    "file_size_kb": file_size / 1024,
                    "build_time_seconds": round(build_time, 2),
                    "error": result.get("message", "æœªçŸ¥é”™è¯¯"),
                    "success": False
                }
                
                print(f"   âŒ å¤„ç†å¤±è´¥: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")
            
            return test_result
            
        except Exception as e:
            print(f"   ğŸ’¥ å¼‚å¸¸: {e}")
            return {
                "file_path": file_path,
                "error": str(e),
                "success": False
            }
    
    async def test_batch_processing(self, data_dir: str) -> Dict[str, Any]:
        """æµ‹è¯•æ‰¹é‡æ–‡ä»¶å¤„ç†"""
        print(f"\nğŸ“ æ‰¹é‡æµ‹è¯•ç›®å½•: {data_dir}")
        
        # è·å–æ‰€æœ‰æ–‡æœ¬æ–‡ä»¶
        text_files = []
        for filename in os.listdir(data_dir):
            if filename.endswith('.txt') and filename != 'combined_corpus.txt':
                text_files.append(os.path.join(data_dir, filename))
        
        print(f"   å‘ç° {len(text_files)} ä¸ªæ–‡æœ¬æ–‡ä»¶")
        
        # æ‰¹é‡å¤„ç†
        batch_start_time = time.time()
        file_results = []
        
        for file_path in text_files[:10]:  # é™åˆ¶å¤„ç†æ•°é‡é¿å…è¿‡é•¿
            file_result = await self.test_single_file_processing(file_path)
            file_results.append(file_result)
            
            # çŸ­æš‚æš‚åœé¿å…APIé™åˆ¶
            await asyncio.sleep(1)
        
        total_batch_time = time.time() - batch_start_time
        
        # ç»Ÿè®¡ç»“æœ
        successful_files = [r for r in file_results if r.get("success", False)]
        failed_files = [r for r in file_results if not r.get("success", False)]
        
        total_triples = sum(r.get("triples_added", 0) for r in successful_files)
        total_size_kb = sum(r.get("file_size_kb", 0) for r in successful_files)
        avg_processing_time = sum(r.get("build_time_seconds", 0) for r in successful_files) / len(successful_files) if successful_files else 0
        
        batch_result = {
            "total_files": len(text_files),
            "processed_files": len(file_results),
            "successful_files": len(successful_files),
            "failed_files": len(failed_files),
            "total_batch_time_seconds": round(total_batch_time, 2),
            "total_triples_extracted": total_triples,
            "total_size_kb": round(total_size_kb, 2),
            "avg_processing_time_seconds": round(avg_processing_time, 2),
            "overall_speed_kb_per_sec": round(total_size_kb / total_batch_time, 2) if total_batch_time > 0 else 0,
            "file_results": file_results
        }
        
        print(f"\nğŸ“Š æ‰¹é‡å¤„ç†ç»“æœ:")
        print(f"   âœ… æˆåŠŸ: {len(successful_files)}/{len(file_results)}")
        print(f"   â±ï¸ æ€»è€—æ—¶: {total_batch_time:.2f}ç§’")
        print(f"   ğŸ“Š æ€»ä¸‰å…ƒç»„: {total_triples}")
        print(f"   ğŸš€ å¹³å‡é€Ÿåº¦: {batch_result['overall_speed_kb_per_sec']} KB/ç§’")
        
        return batch_result
    
    async def test_graph_query_performance(self) -> Dict[str, Any]:
        """æµ‹è¯•å›¾æŸ¥è¯¢æ€§èƒ½"""
        await self._init_service()  # ç¡®ä¿æœåŠ¡å·²åˆå§‹åŒ–
        
        print(f"\nğŸ” æµ‹è¯•å›¾æŸ¥è¯¢æ€§èƒ½...")
        
        # è·å–å½“å‰å›¾ç»Ÿè®¡
        stats = self.kg_service.get_stats()
        basic_stats = stats.get("basic", {})
        
        print(f"   å½“å‰å›¾è§„æ¨¡:")
        print(f"   - èŠ‚ç‚¹æ•°: {basic_stats.get('num_nodes', 0)}")
        print(f"   - è¾¹æ•°: {basic_stats.get('num_edges', 0)}")
        
        query_results = {}
        
        # 1. æµ‹è¯•å…¨å›¾æŸ¥è¯¢
        start_time = time.time()
        full_graph = self.kg_service.storage.get_graph(limit=500)
        query_results["full_graph_query_time"] = time.time() - start_time
        
        print(f"   å…¨å›¾æŸ¥è¯¢(é™åˆ¶500): {query_results['full_graph_query_time']:.3f}ç§’")
        
        # 2. æµ‹è¯•å®ä½“æœç´¢
        if full_graph.nodes:
            start_time = time.time()
            search_results = self.kg_service.search_entities("Python", limit=10)
            query_results["entity_search_time"] = time.time() - start_time
            
            print(f"   å®ä½“æœç´¢: {query_results['entity_search_time']:.3f}ç§’")
            print(f"   æœç´¢ç»“æœ: {len(search_results)} ä¸ªå®ä½“")
            
            # 3. æµ‹è¯•å­å›¾æŸ¥è¯¢
            if search_results:
                center_entity = search_results[0]['id']
                start_time = time.time()
                subgraph = self.kg_service.storage.get_subgraph(center_entity, radius=2)
                query_results["subgraph_query_time"] = time.time() - start_time
                
                print(f"   å­å›¾æŸ¥è¯¢(åŠå¾„2): {query_results['subgraph_query_time']:.3f}ç§’")
                print(f"   å­å›¾è§„æ¨¡: {len(subgraph.nodes)} èŠ‚ç‚¹, {len(subgraph.edges)} è¾¹")
        
        return query_results
    
    async def run_comprehensive_test(self) -> Dict[str, Any]:
        """è¿è¡Œç»¼åˆæµ‹è¯•"""
        print("ğŸš€ å¼€å§‹å¤§è§„æ¨¡çŸ¥è¯†å›¾è°±æµ‹è¯•")
        print("=" * 60)
        
        # 1. ä¸‹è½½æµ‹è¯•æ•°æ®
        sys.path.append('scripts')
        from download_test_data import main as download_data
        
        data_dir, corpus_file = download_data()
        
        print("\n" + "=" * 60)
        
        # 2. æ‰¹é‡å¤„ç†æµ‹è¯•
        batch_result = await self.test_batch_processing(data_dir)
        
        # 3. æŸ¥è¯¢æ€§èƒ½æµ‹è¯•
        query_result = await self.test_graph_query_performance()
        
        # 4. æœ€ç»ˆç»Ÿè®¡
        final_stats = self.kg_service.get_stats()
        
        comprehensive_result = {
            "test_timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "data_source": data_dir,
            "batch_processing": batch_result,
            "query_performance": query_result,
            "final_graph_stats": final_stats,
            "test_summary": {
                "total_processing_time": batch_result.get("total_batch_time_seconds", 0),
                "total_triples": batch_result.get("total_triples_extracted", 0),
                "final_nodes": final_stats.get("basic", {}).get("num_nodes", 0),
                "final_edges": final_stats.get("basic", {}).get("num_edges", 0),
                "success_rate": f"{batch_result.get('successful_files', 0)}/{batch_result.get('processed_files', 0)}"
            }
        }
        
        # ä¿å­˜æµ‹è¯•ç»“æœ
        results_file = "data/kg_benchmark_results.json"
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(comprehensive_result, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“Š ç»¼åˆæµ‹è¯•ç»“æœ:")
        summary = comprehensive_result["test_summary"]
        print(f"   â±ï¸ æ€»å¤„ç†æ—¶é—´: {summary['total_processing_time']}ç§’")
        print(f"   ğŸ“Š æ€»ä¸‰å…ƒç»„æ•°: {summary['total_triples']}")
        print(f"   ğŸŒ æœ€ç»ˆå›¾è§„æ¨¡: {summary['final_nodes']} èŠ‚ç‚¹, {summary['final_edges']} è¾¹")
        print(f"   âœ… æˆåŠŸç‡: {summary['success_rate']}")
        print(f"   ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
        
        return comprehensive_result


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    benchmark = KnowledgeGraphBenchmark(use_mock=True)  # ä½¿ç”¨æ¨¡æ‹ŸæŠ½å–å™¨
    
    try:
        results = await benchmark.run_comprehensive_test()
        
        print(f"\nğŸ‰ å¤§è§„æ¨¡çŸ¥è¯†å›¾è°±æµ‹è¯•å®Œæˆï¼")
        
        # æ˜¾ç¤ºæ€§èƒ½æŒ‡æ ‡
        summary = results["test_summary"]
        if summary["total_triples"] > 0:
            print(f"\nğŸ“ˆ æ€§èƒ½æŒ‡æ ‡:")
            processing_time = summary["total_processing_time"]
            if processing_time > 0:
                print(f"   - ä¸‰å…ƒç»„/ç§’: {summary['total_triples'] / processing_time:.1f}")
                print(f"   - èŠ‚ç‚¹/ç§’: {summary['final_nodes'] / processing_time:.1f}")
        
        # æ£€æŸ¥å›¾è°±è´¨é‡
        final_stats = results["final_graph_stats"]
        basic_stats = final_stats.get("basic", {})
        
        if basic_stats.get("num_nodes", 0) > 0:
            print(f"\nğŸ† å›¾è°±è´¨é‡æŒ‡æ ‡:")
            print(f"   - å¹³å‡åº¦æ•°: {basic_stats.get('avg_degree', 0):.2f}")
            print(f"   - æœ€å¤§åº¦æ•°: {basic_stats.get('max_degree', 0)}")
            
            relationships = basic_stats.get("relationships", {})
            if relationships:
                print(f"   - å…³ç³»ç±»å‹æ•°: {len(relationships)}")
                most_common = max(relationships.items(), key=lambda x: x[1])
                print(f"   - æœ€å¸¸è§å…³ç³»: {most_common[0]} ({most_common[1]}æ¬¡)")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
