"""
é…ç½®ç®¡ç†æ¨¡å— - ç¯å¢ƒå˜é‡éªŒè¯ã€é…ç½®åŠ è½½ã€è®¾ç½®ç®¡ç†

æä¾›ç»Ÿä¸€çš„é…ç½®æ¥å£ï¼Œæ”¯æŒå¤šç¯å¢ƒé…ç½®ã€éªŒè¯å’Œçƒ­é‡è½½åŠŸèƒ½ã€‚
"""

import os
import json
from typing import Dict, List, Optional, Any, Union
from enum import Enum
from pathlib import Path
from dotenv import load_dotenv
from pydantic import Field, validator
from pydantic_settings import BaseSettings


class Environment(str, Enum):
    """ç¯å¢ƒç±»å‹"""
    DEVELOPMENT = "development"
    STAGING = "staging"
    PRODUCTION = "production"
    TESTING = "testing"


class LogLevel(str, Enum):
    """æ—¥å¿—çº§åˆ«"""
    DEBUG = "DEBUG"
    INFO = "INFO"
    WARNING = "WARNING"
    ERROR = "ERROR"
    CRITICAL = "CRITICAL"


class FeynmanSettings(BaseSettings):
    """è´¹æ›¼å­¦ä¹ ç³»ç»Ÿé…ç½®"""
    
    # åŸºç¡€é…ç½®
    environment: Environment = Environment.DEVELOPMENT
    debug: bool = True
    log_level: LogLevel = LogLevel.INFO
    
    # APIæœåŠ¡é…ç½®
    api_host: str = "0.0.0.0"
    api_port: int = 8000
    api_reload: bool = True
    api_workers: int = 1
    
    # LLMæ¨¡å‹é…ç½®
    openai_api_key: Optional[str] = None
    openai_model: str = "gpt-4o"
    openai_base_url: Optional[str] = None
    openai_temperature: float = 0.7
    openai_max_tokens: int = 2000
    
    zhipu_api_key: Optional[str] = None
    zhipu_model: str = "glm-4.5-airx"
    zhipu_base_url: str = "https://open.bigmodel.cn/api/paas/v4/"
    
    # ç¬¬ä¸‰æ–¹APIé…ç½®
    tavily_api_key: Optional[str] = None
    baidu_translate_api_key: Optional[str] = None
    baidu_translate_secret_key: Optional[str] = None
    wolfram_api_key: Optional[str] = None
    youtube_api_key: Optional[str] = None
    news_api_key: Optional[str] = None
    judge0_api_key: Optional[str] = None
    quickchart_api_key: Optional[str] = None
    
    # ç›‘æ§é…ç½®
    monitoring_enabled: bool = True
    metrics_enabled: bool = True
    tracing_enabled: bool = True
    prometheus_port: int = 9090
    
    # LangFuseé…ç½®
    langfuse_public_key: Optional[str] = None
    langfuse_secret_key: Optional[str] = None
    langfuse_host: str = "https://cloud.langfuse.com"
    
    # OpenTelemetryé…ç½®
    otel_service_name: str = "feynman-learning-system"
    otel_exporter_otlp_endpoint: str = "http://localhost:4317"
    
    # æˆæœ¬æ§åˆ¶
    daily_cost_limit_usd: float = 100.0
    monthly_cost_limit_usd: float = 1000.0
    cost_tracking_enabled: bool = True
    token_rate_limit: int = 10000
    
    # è¯·æ±‚é™åˆ¶
    request_timeout_enabled: bool = True
    request_timeout_seconds: float = 300.0
    request_size_limit_enabled: bool = True
    max_request_size_bytes: int = 10485760
    
    # CORSé…ç½®
    cors_origins: List[str] = Field(default_factory=lambda: ["http://localhost:3000", "http://127.0.0.1:3000"])
    
    # çŸ¥è¯†å›¾è°±é…ç½®
    kg_backend: str = Field("local", env="KG_BACKEND")
    kg_storage_path: str = Field("data/knowledge_graph.json", env="KG_STORAGE_PATH")
    kg_max_nodes: int = Field(1000, env="KG_MAX_NODES")
    kg_max_edges: int = Field(5000, env="KG_MAX_EDGES")
    
    # Neo4jé…ç½®
    neo4j_uri: Optional[str] = Field(None, env="NEO4J_URI")
    neo4j_username: Optional[str] = Field(None, env="NEO4J_USERNAME")
    neo4j_password: Optional[str] = Field(None, env="NEO4J_PASSWORD")
    neo4j_database: str = Field("neo4j", env="NEO4J_DATABASE")
    
    @validator('cors_origins', pre=True)
    def parse_cors_origins(cls, v):
        if isinstance(v, str):
            try:
                return json.loads(v)
            except:
                return [origin.strip() for origin in v.split(',')]
        return v
    
    @validator('openai_api_key', 'zhipu_api_key')
    def validate_llm_keys(cls, v, values):
        # è‡³å°‘éœ€è¦ä¸€ä¸ªLLM APIå¯†é’¥
        openai_key = values.get('openai_api_key')
        zhipu_key = values.get('zhipu_api_key')
        if not openai_key and not zhipu_key:
            print("âš ï¸  è­¦å‘Šï¼šæœªè®¾ç½®LLM APIå¯†é’¥ï¼Œç³»ç»Ÿå°†ä»¥å—é™æ¨¡å¼è¿è¡Œ")
        return v
    
    class Config:
        env_file = [".env", "environments/test.env"]  # ä¼˜å…ˆçº§: .env > environments/test.env
        case_sensitive = False
        extra = "ignore"  # å¿½ç•¥é¢å¤–çš„ç¯å¢ƒå˜é‡ï¼Œä¸“æ³¨äºæ ¸å¿ƒé…ç½®


def load_settings(env_file: Optional[str] = None) -> FeynmanSettings:
    """åŠ è½½é…ç½®è®¾ç½®"""
    if env_file:
        load_dotenv(env_file)
    
    return FeynmanSettings()


def validate_configuration(env_file: Optional[str] = None) -> Dict[str, Any]:
    """éªŒè¯é…ç½®å®Œæ•´æ€§"""
    print("ğŸ” æ­£åœ¨éªŒè¯é…ç½®...")
    
    settings = load_settings(env_file)
    
    validation_results = {
        "environment": settings.environment.value,
        "llm_available": bool(settings.openai_api_key or settings.zhipu_api_key),
        "monitoring_enabled": settings.monitoring_enabled,
        "tools_status": {},
        "warnings": [],
        "errors": []
    }
    
    # éªŒè¯LLMé…ç½®
    if settings.openai_api_key:
        validation_results["tools_status"]["openai"] = "âœ… å·²é…ç½®"
    elif settings.zhipu_api_key:
        validation_results["tools_status"]["zhipu"] = "âœ… å·²é…ç½®"
    else:
        validation_results["errors"].append("æœªè®¾ç½®ä»»ä½•LLM APIå¯†é’¥")
    
    # éªŒè¯å·¥å…·API
    tool_apis = {
        "ç½‘ç»œæœç´¢": settings.tavily_api_key,
        "ç¿»è¯‘åŠŸèƒ½": settings.baidu_translate_api_key and settings.baidu_translate_secret_key,
        "æ•°å­¦è®¡ç®—": settings.wolfram_api_key,
        "è§†é¢‘æœç´¢": settings.youtube_api_key,
        "æ–°é—»æœç´¢": settings.news_api_key,
        "ä»£ç æ‰§è¡Œ": settings.judge0_api_key,
        "é«˜çº§å›¾è¡¨": settings.quickchart_api_key
    }
    
    for tool_name, api_key in tool_apis.items():
        if api_key:
            validation_results["tools_status"][tool_name] = "âœ… å·²é…ç½®"
        else:
            validation_results["tools_status"][tool_name] = "âš ï¸  æœªé…ç½®ï¼ˆåŠŸèƒ½å—é™ï¼‰"
    
    # éªŒè¯ç›‘æ§é…ç½®
    if settings.monitoring_enabled:
        if settings.langfuse_public_key and settings.langfuse_secret_key:
            validation_results["tools_status"]["LangFuseè¿½è¸ª"] = "âœ… å·²é…ç½®"
        else:
            validation_results["warnings"].append("ç›‘æ§å·²å¯ç”¨ä½†LangFuseæœªé…ç½®")
    
    # éªŒè¯æˆæœ¬æ§åˆ¶
    if settings.cost_tracking_enabled:
        if settings.daily_cost_limit_usd > 0:
            validation_results["tools_status"]["æˆæœ¬æ§åˆ¶"] = f"âœ… æ¯æ—¥é™åˆ¶: ${settings.daily_cost_limit_usd}"
        else:
            validation_results["warnings"].append("æˆæœ¬è¿½è¸ªå·²å¯ç”¨ä½†æœªè®¾ç½®é™åˆ¶")
    
    # æ‰“å°éªŒè¯ç»“æœ
    print(f"\nğŸ“Š é…ç½®éªŒè¯ç»“æœ ({settings.environment.value} ç¯å¢ƒ):")
    print(f"ğŸ”‘ LLMå¯ç”¨: {'âœ…' if validation_results['llm_available'] else 'âŒ'}")
    print(f"ğŸ“ˆ ç›‘æ§å¯ç”¨: {'âœ…' if validation_results['monitoring_enabled'] else 'âŒ'}")
    
    print(f"\nğŸ› ï¸  å·¥å…·çŠ¶æ€:")
    for tool, status in validation_results["tools_status"].items():
        print(f"  {tool}: {status}")
    
    if validation_results["warnings"]:
        print(f"\nâš ï¸  è­¦å‘Š:")
        for warning in validation_results["warnings"]:
            print(f"  - {warning}")
    
    if validation_results["errors"]:
        print(f"\nâŒ é”™è¯¯:")
        for error in validation_results["errors"]:
            print(f"  - {error}")
    
    return validation_results


def get_api_key_setup_guide() -> str:
    """è¿”å›APIå¯†é’¥è®¾ç½®æŒ‡å—"""
    return """
ğŸ”‘ APIå¯†é’¥è®¾ç½®æŒ‡å—

ğŸ“‹ å¿…éœ€é…ç½®:
1. OpenAI APIå¯†é’¥: https://platform.openai.com/api-keys
   æˆ–
2. æ™ºè°±AI APIå¯†é’¥: https://open.bigmodel.cn/

ğŸ› ï¸  å¯é€‰å·¥å…·APIå¯†é’¥:
- Tavilyæœç´¢: https://tavily.com
- ç™¾åº¦ç¿»è¯‘: https://fanyi-api.baidu.com
- WolframAlpha: https://developer.wolframalpha.com
- YouTube Data API: https://developers.google.com/youtube/v3
- NewsAPI: https://newsapi.org
- Judge0ä»£ç æ‰§è¡Œ: https://rapidapi.com/judge0-official
- QuickChartå›¾è¡¨: https://quickchart.io

ğŸ“ˆ ç›‘æ§æœåŠ¡APIå¯†é’¥:
- LangFuse: https://langfuse.com

é…ç½®å®Œæˆåè¿è¡Œ: uv run python -c "
import sys; sys.path.insert(0, 'src')
from feynman.core.config.settings import validate_configuration
validate_configuration()
"
"""


# å…¨å±€é…ç½®å®ä¾‹
_settings_instance = None

def get_settings() -> FeynmanSettings:
    """è·å–å…¨å±€é…ç½®å®ä¾‹"""
    global _settings_instance
    if _settings_instance is None:
        _settings_instance = load_settings()
    return _settings_instance