"""
ç–‘ç‚¹ç†è§£Agent - æ™ºèƒ½åˆ†æç”¨æˆ·è§£é‡Šä¸­çš„çŸ¥è¯†ç¼ºå£

è¿™ä¸ªAgentä¸“é—¨è´Ÿè´£ç†è§£å’Œåˆ†æç”¨æˆ·çš„è§£é‡Šï¼Œè¯†åˆ«çœŸæ­£éœ€è¦æ¾„æ¸…çš„çŸ¥è¯†ç‚¹ã€‚
ä¸åŒäºç®€å•çš„æ–‡æœ¬è§£æï¼Œè¿™é‡Œä½¿ç”¨ä¸“é—¨çš„LLMæ¥è¿›è¡Œè¯­ä¹‰ç†è§£ã€‚
"""

import json
from typing import List, Dict, Any, Optional
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_community.chat_models import ChatZhipuAI
from pydantic import BaseModel, Field

from feynman.agents.parsers.output_parser import AnalysisResult, UnclearPoint, ConfidenceLevel
from feynman.core.config.settings import get_settings
from .agent_protocol import (
    AgentInterface, AgentType, AgentMetadata, AgentCapability,
    AgentTask, AgentResponse, ConversationContext, AgentMessage,
    create_response
)
from typing import Optional


# =============================================================================
# å†…åµŒæç¤ºè¯æ¨¡æ¿
# =============================================================================

EXPLANATION_ANALYZER_SYSTEM_PROMPT = """ä½ æ˜¯è´¹æ›¼å­¦ä¹ ç³»ç»Ÿçš„è§£é‡Šåˆ†æä¸“å®¶Agentï¼Œè´Ÿè´£æ·±åº¦ç†è§£å’Œåˆ†æç”¨æˆ·çš„çŸ¥è¯†è§£é‡Šã€‚

## ğŸ¯ æ ¸å¿ƒèŒè´£

1. **æ·±åº¦ç†è§£åˆ†æ**
   - å…¨é¢ç†è§£ç”¨æˆ·è§£é‡Šçš„å†…å®¹å’Œç»“æ„
   - è¯†åˆ«è§£é‡Šä¸­çš„å…³é”®æ¦‚å¿µå’Œé€»è¾‘å…³ç³»
   - è¯„ä¼°è§£é‡Šçš„å®Œæ•´æ€§å’Œå‡†ç¡®æ€§

2. **ç–‘ç‚¹æ™ºèƒ½è¯†åˆ«**
   - å‘ç°é€»è¾‘è·³è·ƒå’Œæ¨ç†ç¼ºå£
   - è¯†åˆ«æ¦‚å¿µæ¨¡ç³Šå’Œå®šä¹‰ä¸æ¸…
   - æ ‡è®°éœ€è¦è¿›ä¸€æ­¥æ¾„æ¸…çš„çŸ¥è¯†ç‚¹

3. **çŸ¥è¯†ç»“æ„åˆ†æ**
   - åˆ†æçŸ¥è¯†çš„å±‚æ¬¡ç»“æ„å’Œç»„ç»‡æ–¹å¼
   - è¯„ä¼°æ¦‚å¿µä¹‹é—´çš„å…³è”å’Œä¾èµ–å…³ç³»
   - è¯†åˆ«çŸ¥è¯†ä½“ç³»çš„å®Œæ•´æ€§å’Œä¸€è‡´æ€§

## ğŸ” åˆ†æç»´åº¦

### 1. æ¦‚å¿µå‡†ç¡®æ€§ (Concept Accuracy)
- ä¸“ä¸šæœ¯è¯­ä½¿ç”¨æ˜¯å¦æ­£ç¡®
- æ¦‚å¿µå®šä¹‰æ˜¯å¦å‡†ç¡®å®Œæ•´
- æ¦‚å¿µè¾¹ç•Œæ˜¯å¦æ¸…æ™°

### 2. é€»è¾‘è¿è´¯æ€§ (Logical Coherence)
- æ¨ç†è¿‡ç¨‹æ˜¯å¦åˆç†
- è®ºè¯æ˜¯å¦å……åˆ†
- å› æœå…³ç³»æ˜¯å¦æˆç«‹

### 3. ç»“æ„å®Œæ•´æ€§ (Structural Completeness)
- è§£é‡Šæ˜¯å¦æ¶µç›–å…³é”®è¦ç´ 
- çŸ¥è¯†ç‚¹æ˜¯å¦æœ‰é—æ¼
- å±‚æ¬¡ç»“æ„æ˜¯å¦æ¸…æ™°

### 4. åº”ç”¨æœºåˆ¶ (Application Mechanism)
- åŸç†å¦‚ä½•åœ¨å®é™…ä¸­è¿ä½œ
- é€‚ç”¨æ¡ä»¶å’ŒèŒƒå›´
- ä¾‹å¤–æƒ…å†µå’Œé™åˆ¶

### 5. è¾¹ç•Œæ¡ä»¶ (Boundary Conditions)
- ç†è®ºæˆ–æ¦‚å¿µçš„é€‚ç”¨è¾¹ç•Œ
- ä¸ç›¸å…³æ¦‚å¿µçš„åŒºåˆ«
- ç‰¹æ®Šæƒ…å†µçš„å¤„ç†

## ğŸ“Š ç–‘ç‚¹åˆ†ç±»ä½“ç³»

- **Concept**: æ¦‚å¿µå®šä¹‰ã€æœ¯è¯­ç†è§£ç›¸å…³ç–‘ç‚¹
- **Logic**: é€»è¾‘æ¨ç†ã€å› æœå…³ç³»ç›¸å…³ç–‘ç‚¹  
- **Mechanism**: å·¥ä½œåŸç†ã€è¿ä½œæœºåˆ¶ç›¸å…³ç–‘ç‚¹
- **Application**: å®é™…åº”ç”¨ã€åœºæ™¯è¿ç”¨ç›¸å…³ç–‘ç‚¹
- **Boundary**: é€‚ç”¨èŒƒå›´ã€è¾¹ç•Œæ¡ä»¶ç›¸å…³ç–‘ç‚¹

## ğŸ¯ ç½®ä¿¡åº¦è¯„ä¼°

- **High**: æ˜ç¡®çš„é€»è¾‘é—®é¢˜æˆ–äº‹å®é”™è¯¯
- **Medium**: éœ€è¦è¿›ä¸€æ­¥æ¾„æ¸…çš„æ¦‚å¿µ
- **Low**: å¯ä»¥æ·±å…¥æ¢è®¨çš„è¯é¢˜

## ğŸ“¤ è¾“å‡ºæ ¼å¼

è¯·ä»¥JSONæ ¼å¼è¾“å‡ºåˆ†æç»“æœï¼š

```json
{
    "unclear_points": [
        {
            "content": "å…·ä½“çš„ç–‘ç‚¹æè¿°",
            "category": "concept|logic|mechanism|application|boundary",
            "confidence": "high|medium|low",
            "reasoning": "è¯†åˆ«æ­¤ç–‘ç‚¹çš„è¯¦ç»†åŸå› ",
            "educational_value": "æ¾„æ¸…æ­¤ç–‘ç‚¹çš„æ•™è‚²ä»·å€¼",
            "suggested_approach": "å»ºè®®çš„æ¾„æ¸…æ–¹å¼",
            "priority": 2
        }
    ],
    "is_complete": false,
    "summary": "æ•´ä½“åˆ†ææ€»ç»“",
    "understanding_quality": "excellent|good|fair|poor",
    "key_concepts": [
        "è¯†åˆ«å‡ºçš„å…³é”®æ¦‚å¿µ1",
        "å…³é”®æ¦‚å¿µ2"
    ],
    "knowledge_depth": "surface|intermediate|deep|expert",
    "improvement_suggestions": [
        "æ”¹è¿›å»ºè®®1",
        "æ”¹è¿›å»ºè®®2"
    ],
    "analysis_metadata": {
        "complexity_level": "low|medium|high|very_high",
        "analysis_confidence": 0.85,
        "processing_notes": "åˆ†æè¿‡ç¨‹ä¸­çš„é‡è¦è§‚å¯Ÿ"
    }
}
```

è¯·ä»¥è´¹æ›¼å­¦ä¹ æ³•çš„è§’åº¦ï¼Œæ·±å…¥åˆ†æç”¨æˆ·è§£é‡Šï¼Œè¯†åˆ«æ‰€æœ‰éœ€è¦æ¾„æ¸…çš„ç–‘ç‚¹ã€‚"""


EXPLANATION_UNDERSTANDING_TEMPLATE = """è¯·æ·±åº¦åˆ†æä»¥ä¸‹ç”¨æˆ·è§£é‡Šï¼š

## ğŸ“š å­¦ä¹ ä¸»é¢˜
{topic}

## ğŸ“ ç”¨æˆ·è§£é‡Šå†…å®¹
{user_explanation}

## ğŸ¯ åˆ†æè¦æ±‚
- åˆ†ææ·±åº¦: {analysis_depth}
- å…³æ³¨é‡ç‚¹: {focus_areas}
- è´¨é‡æ ‡å‡†: {quality_standards}

## ğŸ“Š èƒŒæ™¯ä¿¡æ¯
- é¢„æœŸçŸ¥è¯†æ°´å¹³: {expected_knowledge_level}
- å­¦ä¹ ç›®æ ‡: {learning_objectives}
- æ—¶é—´çº¦æŸ: {time_constraints}

è¯·å¯¹ç”¨æˆ·çš„è§£é‡Šè¿›è¡Œå…¨é¢åˆ†æï¼Œè¯†åˆ«æ‰€æœ‰éœ€è¦è¿›ä¸€æ­¥æ¾„æ¸…çš„ç–‘ç‚¹ï¼Œå¹¶è¯„ä¼°è§£é‡Šçš„è´¨é‡å’Œå®Œæ•´æ€§ã€‚"""


DOUBT_IDENTIFICATION_TEMPLATE = """ä¸»é¢˜: {topic}

ç”¨æˆ·è§£é‡Š:
{explanation}

åˆ†ææ´å¯Ÿ:
- å…³é”®æ¦‚å¿µ: {key_concepts}
- é€»è¾‘æµç¨‹: {logical_flow} 
- çŸ¥è¯†æ·±åº¦: {knowledge_depth}
- æ½œåœ¨ç¼ºå£: {potential_gaps}
- æ•™å­¦è´¨é‡: {teaching_quality}

è¯·åŸºäºè¿™äº›æ´å¯Ÿï¼Œè¯†åˆ«å‡ºéœ€è¦æ¾„æ¸…çš„å…·ä½“ç–‘ç‚¹ã€‚"""


class ExplanationInsight(BaseModel):
    """è§£é‡Šæ´å¯Ÿ - Agentå¯¹ç”¨æˆ·è§£é‡Šçš„æ·±åº¦ç†è§£"""
    
    key_concepts: List[str] = Field(default_factory=list, description="è§£é‡Šä¸­çš„å…³é”®æ¦‚å¿µ")
    logical_flow: str = Field(default="", description="é€»è¾‘æµç¨‹åˆ†æ")
    knowledge_depth: str = Field(default="surface", description="çŸ¥è¯†æ·±åº¦è¯„ä¼°: surface/intermediate/deep")
    potential_gaps: List[str] = Field(default_factory=list, description="æ½œåœ¨çŸ¥è¯†ç¼ºå£")
    teaching_quality: str = Field(default="", description="æ•™å­¦è´¨é‡è¯„ä¼°")


class ExplanationAnalyzer(AgentInterface):
    """ç–‘ç‚¹ç†è§£Agent - æ™ºèƒ½åˆ†æç”¨æˆ·è§£é‡Š"""
    
    def __init__(self):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        
        # å®šä¹‰Agentèƒ½åŠ›
        capabilities = [
            AgentCapability(
                name="explanation_analysis",
                description="åˆ†æç”¨æˆ·è§£é‡Šï¼Œè¯†åˆ«çŸ¥è¯†ç¼ºå£",
                input_types=["text", "explanation", "topic"],
                output_types=["analysis_result", "unclear_points"],
                complexity_level="complex"
            ),
            AgentCapability(
                name="concept_understanding",
                description="æ·±åº¦ç†è§£æ¦‚å¿µå’Œé€»è¾‘å…³ç³»",
                input_types=["explanation", "concept"],
                output_types=["concept_analysis", "insight"],
                complexity_level="medium"
            ),
            AgentCapability(
                name="doubt_identification",
                description="è¯†åˆ«éœ€è¦æ¾„æ¸…çš„ç–‘ç‚¹",
                input_types=["explanation", "insight"],
                output_types=["doubt_list", "unclear_points"],
                complexity_level="complex"
            )
        ]
        
        # åˆå§‹åŒ–å…ƒæ•°æ®
        metadata = AgentMetadata(
            agent_type=AgentType.EXPLANATION_ANALYZER,
            name="ExplanationAnalyzer",
            version="1.0.0",
            capabilities=capabilities,
            dependencies=[],  # ç‹¬ç«‹è¿è¡Œï¼Œä¸ä¾èµ–å…¶ä»–Agent
            max_concurrent_tasks=2
        )
        
        super().__init__(metadata)
        
        settings = get_settings()
        
        # ä¼˜å…ˆä½¿ç”¨OpenAI
        if settings.openai_api_key:
            self.llm = ChatOpenAI(
                api_key=settings.openai_api_key,
                model=settings.openai_model,
                temperature=0.3  # åˆ†æä»»åŠ¡éœ€è¦æ›´ç¨³å®šçš„è¾“å‡º
            )
        elif settings.llm_provider == "zhipu" and settings.zhipu_api_key:
            self.llm = ChatZhipuAI(
                api_key=settings.zhipu_api_key,
                model=settings.zhipu_model,
                temperature=0.3
            )
        else:
            raise ValueError("æœªé…ç½®å¯ç”¨çš„LLMæ¨¡å‹")
    
    def analyze_explanation(self, topic: str, user_explanation: str, context: Optional[Dict] = None) -> AnalysisResult:
        """
        åˆ†æç”¨æˆ·è§£é‡Šï¼Œè¯†åˆ«éœ€è¦æ¾„æ¸…çš„ç–‘ç‚¹
        
        Args:
            topic: å­¦ä¹ ä¸»é¢˜
            user_explanation: ç”¨æˆ·çš„è§£é‡Šå†…å®¹
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå†å²å¯¹è¯ç­‰ï¼‰
            
        Returns:
            AnalysisResult: ç»“æ„åŒ–çš„åˆ†æç»“æœ
        """
        
        # ç¬¬ä¸€æ­¥ï¼šæ·±åº¦ç†è§£ç”¨æˆ·è§£é‡Š
        insight = self._understand_explanation(topic, user_explanation, context)
        
        # ç¬¬äºŒæ­¥ï¼šåŸºäºç†è§£è¯†åˆ«ç–‘ç‚¹
        unclear_points = self._identify_unclear_points(topic, user_explanation, insight)
        
        # ç¬¬ä¸‰æ­¥ï¼šè¯„ä¼°å®Œæ•´æ€§
        is_complete = len(unclear_points) == 0
        
        # ç¬¬å››æ­¥ï¼šç”Ÿæˆåˆ†ææ€»ç»“
        summary = self._generate_summary(insight, unclear_points, is_complete)
        
        return AnalysisResult(
            unclear_points=unclear_points,
            is_complete=is_complete,
            summary=summary
        )
    
    async def process_task(self, task: AgentTask, context: ConversationContext) -> AgentResponse:
        """å¤„ç†åˆ†æä»»åŠ¡"""
        try:
            # æå–ä»»åŠ¡æ•°æ®
            topic = task.input_data.get("topic", "")
            explanation = task.input_data.get("explanation", "")
            
            # æ‰§è¡Œåˆ†æ
            analysis_result = self.analyze_explanation(topic, explanation, {
                "session_id": context.session_id,
                "conversation_history": context.conversation_history
            })
            
            # æ„å»ºå“åº”
            result_data = {
                "unclear_points": [point.dict() for point in analysis_result.unclear_points],
                "is_complete": analysis_result.is_complete,
                "summary": analysis_result.summary
            }
            
            return create_response(
                agent_id=self.metadata.agent_id,
                agent_type=self.metadata.agent_type,
                task_id=task.task_id,
                success=True,
                result=result_data,
                processing_time=0.0  # å®é™…åº”è¯¥è®°å½•çœŸå®æ—¶é—´
            )
            
        except Exception as e:
            return create_response(
                agent_id=self.metadata.agent_id,
                agent_type=self.metadata.agent_type,
                task_id=task.task_id,
                success=False,
                error=str(e),
                processing_time=0.0
            )
    
    async def handle_message(self, message: AgentMessage) -> Optional[AgentMessage]:
        """å¤„ç†æ¶ˆæ¯"""
        # ExplanationAnalyzeré€šå¸¸ä¸éœ€è¦å¤„ç†ç›´æ¥æ¶ˆæ¯
        return None
    
    def _understand_explanation(self, topic: str, explanation: str, context: Optional[Dict] = None) -> ExplanationInsight:
        """æ·±åº¦ç†è§£ç”¨æˆ·è§£é‡Š"""
        
        understanding_prompt = ChatPromptTemplate.from_messages([
            ("system", EXPLANATION_ANALYZER_SYSTEM_PROMPT),
            ("human", EXPLANATION_UNDERSTANDING_TEMPLATE)
        ])
        
        context_info = ""
        if context:
            context_info = f"ä¸Šä¸‹æ–‡ä¿¡æ¯: {json.dumps(context, ensure_ascii=False)}"
        
        messages = understanding_prompt.format_messages(
            topic=topic,
            explanation=explanation,
            context_info=context_info
        )
        
        response = self.llm.invoke(messages)
        
        try:
            # å°è¯•è§£æJSONå“åº”
            insight_data = json.loads(response.content)
            return ExplanationInsight(**insight_data)
        except (json.JSONDecodeError, ValueError):
            # å¦‚æœJSONè§£æå¤±è´¥ï¼Œåˆ›å»ºåŸºç¡€æ´å¯Ÿ
            return ExplanationInsight(
                key_concepts=self._extract_keywords(explanation),
                logical_flow="è§£æå¤±è´¥ï¼Œæ— æ³•åˆ†æé€»è¾‘æµç¨‹",
                knowledge_depth="unknown",
                potential_gaps=["éœ€è¦è¿›ä¸€æ­¥åˆ†æ"],
                teaching_quality="æ— æ³•è¯„ä¼°"
            )
    
    def _identify_unclear_points(self, topic: str, explanation: str, insight: ExplanationInsight) -> List[UnclearPoint]:
        """åŸºäºç†è§£æ´å¯Ÿè¯†åˆ«å…·ä½“ç–‘ç‚¹"""
        
        identification_prompt = ChatPromptTemplate.from_messages([
            ("system", EXPLANATION_ANALYZER_SYSTEM_PROMPT),
            ("human", DOUBT_IDENTIFICATION_TEMPLATE)
        ])
        
        messages = identification_prompt.format_messages(
            topic=topic,
            explanation=explanation,
            key_concepts=", ".join(insight.key_concepts),
            logical_flow=insight.logical_flow,
            knowledge_depth=insight.knowledge_depth,
            potential_gaps=", ".join(insight.potential_gaps),
            teaching_quality=insight.teaching_quality
        )
        
        response = self.llm.invoke(messages)
        
        try:
            # è§£æç–‘ç‚¹åˆ—è¡¨
            unclear_data = json.loads(response.content)
            unclear_points = []
            
            if isinstance(unclear_data, list):
                for item in unclear_data:
                    if isinstance(item, dict):
                        unclear_points.append(UnclearPoint(**item))
                    elif isinstance(item, str):
                        unclear_points.append(UnclearPoint(content=item))
            elif isinstance(unclear_data, dict) and "unclear_points" in unclear_data:
                for item in unclear_data["unclear_points"]:
                    if isinstance(item, dict):
                        unclear_points.append(UnclearPoint(**item))
                    elif isinstance(item, str):
                        unclear_points.append(UnclearPoint(content=item))
            
            return unclear_points
            
        except (json.JSONDecodeError, ValueError) as e:
            print(f"ç–‘ç‚¹è¯†åˆ«JSONè§£æå¤±è´¥: {e}")
            # é™çº§ç­–ç•¥ï¼šä»å“åº”ä¸­æå–å…³é”®ä¿¡æ¯
            return self._extract_unclear_points_from_text(response.content)
    
    def _generate_summary(self, insight: ExplanationInsight, unclear_points: List[UnclearPoint], is_complete: bool) -> str:
        """ç”Ÿæˆåˆ†ææ€»ç»“"""
        if is_complete:
            return f"è§£é‡Šå®Œæ•´æ¸…æ™°ï¼Œæ¶µç›–äº†{len(insight.key_concepts)}ä¸ªå…³é”®æ¦‚å¿µï¼Œé€»è¾‘æµç¨‹æ¸…æ¥šï¼Œæ— éœ€è¿›ä¸€æ­¥æ¾„æ¸…ã€‚"
        
        summary_parts = []
        summary_parts.append(f"è¯†åˆ«åˆ°{len(unclear_points)}ä¸ªç–‘ç‚¹")
        
        if insight.knowledge_depth:
            depth_desc = {
                "surface": "è¡¨é¢å±‚æ¬¡",
                "intermediate": "ä¸­ç­‰æ·±åº¦", 
                "deep": "æ·±å…¥å±‚æ¬¡"
            }
            summary_parts.append(f"çŸ¥è¯†æ·±åº¦ä¸º{depth_desc.get(insight.knowledge_depth, insight.knowledge_depth)}")
        
        # æŒ‰ç½®ä¿¡åº¦åˆ†ç»„
        high_confidence = [p for p in unclear_points if p.confidence == ConfidenceLevel.HIGH]
        medium_confidence = [p for p in unclear_points if p.confidence == ConfidenceLevel.MEDIUM]
        low_confidence = [p for p in unclear_points if p.confidence == ConfidenceLevel.LOW]
        
        if high_confidence:
            summary_parts.append(f"åŒ…å«{len(high_confidence)}ä¸ªé«˜ä¼˜å…ˆçº§ç–‘ç‚¹")
        if medium_confidence:
            summary_parts.append(f"{len(medium_confidence)}ä¸ªä¸­ç­‰ä¼˜å…ˆçº§ç–‘ç‚¹")
        if low_confidence:
            summary_parts.append(f"{len(low_confidence)}ä¸ªå»¶ä¼¸æ¢è®¨ç‚¹")
        
        return "ï¼Œ".join(summary_parts) + "ã€‚"
    
    def _extract_keywords(self, text: str) -> List[str]:
        """ç®€å•çš„å…³é”®è¯æå–ï¼ˆé™çº§æ–¹æ¡ˆï¼‰"""
        import re
        # ç®€å•çš„ä¸­æ–‡å…³é”®è¯æå–
        words = re.findall(r'[\u4e00-\u9fff]+', text)
        # è¿‡æ»¤é•¿åº¦ï¼Œå»é‡ï¼Œå–å‰10ä¸ª
        keywords = list(set([w for w in words if len(w) >= 2]))[:10]
        return keywords
    
    def _extract_unclear_points_from_text(self, text: str) -> List[UnclearPoint]:
        """ä»æ–‡æœ¬ä¸­æå–ç–‘ç‚¹ï¼ˆé™çº§æ–¹æ¡ˆï¼‰"""
        lines = text.split('\n')
        points = []
        
        for line in lines:
            line = line.strip()
            if any(keyword in line for keyword in ['ç–‘ç‚¹', 'ä¸æ¸…æ¥š', 'éœ€è¦', 'ä»€ä¹ˆæ˜¯', 'å¦‚ä½•', 'ä¸ºä»€ä¹ˆ']):
                if len(line) > 10:  # è¿‡æ»¤å¤ªçŸ­çš„è¡Œ
                    points.append(UnclearPoint(
                        content=line,
                        confidence=ConfidenceLevel.MEDIUM,
                        reasoning="æ–‡æœ¬æå–é™çº§ç­–ç•¥"
                    ))
        
        if not points:
            points.append(UnclearPoint(
                content="éœ€è¦è¿›ä¸€æ­¥æ¾„æ¸…è§£é‡Šä¸­çš„å…³é”®æ¦‚å¿µ",
                confidence=ConfidenceLevel.LOW,
                reasoning="æ— æ³•è¯†åˆ«å…·ä½“ç–‘ç‚¹ï¼Œä½¿ç”¨é€šç”¨ç–‘ç‚¹"
            ))
        
        return points[:5]  # æœ€å¤šè¿”å›5ä¸ªç–‘ç‚¹
