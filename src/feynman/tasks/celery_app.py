"""
Celery ä»»åŠ¡é˜Ÿåˆ—åº”ç”¨é…ç½®

è¿™ä¸ªæ¨¡å—åˆå§‹åŒ– Celery åº”ç”¨ï¼Œä½¿ç”¨ Redis ä½œä¸ºæ¶ˆæ¯ä»£ç†å’Œç»“æœåç«¯ã€‚
æ”¯æŒè´¹æ›¼å­¦ä¹ ç³»ç»Ÿçš„å¼‚æ­¥ä»»åŠ¡å¤„ç†ï¼ŒåŒ…æ‹¬ï¼š
- è®°å¿†å›ºåŒ–ä»»åŠ¡
- çŸ¥è¯†å›¾è°±æ„å»ºä»»åŠ¡
- æˆæœ¬è¿½è¸ªä»»åŠ¡
- å…¶ä»–åå°å¤„ç†ä»»åŠ¡
"""

import os
from celery import Celery
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡ - ä¼˜å…ˆæ ¹ç›®å½• .envï¼Œå…¼å®¹æ—§è·¯å¾„
load_dotenv(".env")
load_dotenv("environments/test.env")

# è·å–Redisè¿æ¥URL - ä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„Redis Cloudé…ç½®
redis_url = os.getenv("REDIS_URL")
if not redis_url:
    raise ValueError("REDIS_URLç¯å¢ƒå˜é‡æœªè®¾ç½®ï¼Œè¯·æ£€æŸ¥.envæˆ–environments/test.envé…ç½®æ–‡ä»¶")

print(f"ğŸ”— Celeryä½¿ç”¨Redis: {redis_url[:20]}...{redis_url[-20:]}")

# åˆ›å»ºCeleryåº”ç”¨å®ä¾‹
celery_app = Celery(
    "feynman_tasks",
    broker=redis_url,        # ä½¿ç”¨Redisä½œä¸ºæ¶ˆæ¯ä»£ç†
    backend=redis_url        # ä½¿ç”¨Rediså­˜å‚¨ä»»åŠ¡ç»“æœ
)

# Celeryé…ç½®
celery_app.conf.update(
    # åºåˆ—åŒ–è®¾ç½®
    task_serializer="json",
    result_serializer="json", 
    accept_content=["json"],
    
    # æ—¶åŒºè®¾ç½®
    timezone="Asia/Shanghai",
    enable_utc=True,
    
    # ä»»åŠ¡è¿½è¸ªå’Œè¶…æ—¶
    task_track_started=True,
    task_time_limit=300,     # å•ä»»åŠ¡è¶…æ—¶5åˆ†é’Ÿ
    task_soft_time_limit=240, # è½¯è¶…æ—¶4åˆ†é’Ÿ
    
    # é‡è¯•è®¾ç½®
    task_acks_late=True,     # ä»»åŠ¡æ‰§è¡Œåæ‰ç¡®è®¤
    task_reject_on_worker_lost=True,
    
    # ç»“æœè¿‡æœŸæ—¶é—´
    result_expires=3600,     # 1å°æ—¶åæ¸…ç†ç»“æœ
    
    # Workerè®¾ç½®
    worker_prefetch_multiplier=1,  # æ¯æ¬¡åªæ‹‰å–ä¸€ä¸ªä»»åŠ¡
    worker_max_tasks_per_child=1000,  # æ¯ä¸ªworkerå¤„ç†1000ä¸ªä»»åŠ¡åé‡å¯
    
    # é˜Ÿåˆ—è·¯ç”±è®¾ç½®
    task_routes={
        'feynman.tasks.memory.*': {'queue': 'memory'},
        'feynman.tasks.knowledge.*': {'queue': 'knowledge'},
        'feynman.tasks.monitoring.*': {'queue': 'monitoring'},
    },
    
    # é»˜è®¤é˜Ÿåˆ—
    task_default_queue='default',
    task_default_exchange='default',
    task_default_routing_key='default',
    
    # ç›‘æ§è®¾ç½®
    worker_send_task_events=True,
    task_send_sent_event=True,
)

# ä»»åŠ¡å‘ç°é…ç½® - è‡ªåŠ¨å‘ç°ä»»åŠ¡æ¨¡å—
celery_app.autodiscover_tasks([
    'feynman.tasks.memory',
    'feynman.tasks.knowledge', 
    'feynman.tasks.monitoring',
])

# å¯åŠ¨äº‹ä»¶å¤„ç†
@celery_app.on_after_configure.connect
def setup_periodic_tasks(sender, **kwargs):
    """è®¾ç½®å‘¨æœŸæ€§ä»»åŠ¡"""
    # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ å®šæ—¶ä»»åŠ¡
    # sender.add_periodic_task(300.0, cleanup_expired_sessions.s(), name='cleanup sessions every 5min')
    pass

# ä»»åŠ¡å¤±è´¥å¤„ç†
@celery_app.task(bind=True)
def debug_task(self):
    """è°ƒè¯•ä»»åŠ¡ï¼Œç”¨äºæµ‹è¯•Celeryè¿æ¥"""
    print(f'Request: {self.request!r}')
    return "Debug task completed successfully"

if __name__ == '__main__':
    celery_app.start()
